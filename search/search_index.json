{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#introduction","title":"Introduction","text":"<p>GLIM is a versatile and extensible range-based 3D mapping framework.</p> <ul> <li>Accuracy: GLIM is based on direct multi-scan registration error minimization on factor graphs that enables to accurately retain the consistency of mappint results. GPU acceleration is supported to maximize the mapping speed and quality.</li> <li>Easy-to-use: GLIM offers an interactive map correction interface that enables the user to manually correct mapping failures and easily refine mapping results.</li> <li>Versatility: As we eliminated sensor-specific processes, GLIM can be applied to any kind of range sensors including:<ul> <li>Spinning-type LiDAR (e.g., Velodyne HDL32e and Ouster OS1)</li> <li>Non-repetitive scan LiDAR (e.g., Livox Avia and MID360)</li> <li>Solid-state LiDAR (e.g., Intel Realsense L515)</li> <li>RGB-D camera (e.g., Microsoft Azure Kinect)</li> </ul> </li> <li>Extensibility: GLIM provides the global callback slot mechanism that allows to access the internal states of the mapping process and insert additional constraints to the factor graph. We also release glim_ext that offers example implementations of several extension functions (e.g., explicit loop detection, LiDAR-Visual-Inertial odometry estimation).</li> </ul> <p>Tested on Ubuntu 22.04 / 24.04 with CUDA 12.2 / 12.6 / 13.1, and NVIDIA Jetson Orin (Jetpack 6.1).</p> <p> </p>"},{"location":"index.html#video","title":"Video","text":""},{"location":"index.html#robustness-test","title":"Robustness test","text":""},{"location":"index.html#mapping-with-various-range-sensors","title":"Mapping with various range sensors","text":""},{"location":"index.html#outdoor-driving-test-with-livox-mid360","title":"Outdoor driving test with Livox MID360","text":""},{"location":"index.html#merging-multiple-mapping-sessions","title":"Merging Multiple Mapping Sessions","text":""},{"location":"index.html#manual-object-removal","title":"Manual Object Removal","text":"<p>See more in Extension modules and Demo pages.</p>"},{"location":"index.html#contact","title":"Contact","text":"<p>Kenji Koide   National Institute of Advanced Industrial Science and Technology (AIST), Japan</p>"},{"location":"api.html","title":"API list","text":""},{"location":"api.html#doxygen-generated-api-list","title":"Doxygen generated API list","text":"<ul> <li>gtsam_points: GTSAM factors for range-based SLAM</li> <li>glim: LiDAR-IMU localization and mapping</li> </ul>"},{"location":"api.html#related-repositories","title":"Related Repositories","text":"<ul> <li>gtsam_points (https://github.com/koide3/gtsam_points)</li> <li>glim (https://github.com/koide3/glim)</li> <li>~~glim_ros1 (https://github.com/koide3/glim_ros1)~~</li> <li>glim_ros2 (https://github.com/koide3/glim_ros2)</li> <li>glim_ext (https://github.com/koide3/glim_ext)</li> </ul>"},{"location":"demo.html","title":"Demo data","text":"<p>See more videos at Video Gallery.</p>"},{"location":"demo.html#mapping-with-various-range-sensors","title":"Mapping with various range sensors","text":"<ul> <li>Download dataset</li> <li>config_versatile.tar.gz</li> </ul> <pre><code>ros2 run glim_ros glim_rosbag --ros-args -p config_path:=$(realpath config/kinect) kinect\n</code></pre> <p>Tip</p> <p>The same parameter set was used for all the sensors.</p> <p>Warning</p> <p>As can be seen in the video, the quality of point clouds of stereo-based sensors (D455 and ZED2i) is not very good, and GLIM, which is based on point cloud matching, does not always work well with these sensors. We recommend using other vision-based SLAM packages for stereo sensors.</p>"},{"location":"demo.html#flat-wall-experiment","title":"Flat wall experiment","text":"<ul> <li>Download dataset </li> <li>config_flatwall.tar.gz</li> </ul>"},{"location":"demo.html#outdoor-driving-test-with-livox-mid360","title":"Outdoor driving test with Livox MID360","text":"<ul> <li>Download dataset</li> </ul> <p>Tip</p> <p>Change parameters in <code>config_ros.json</code> as follows (see also the sensor setup guide):</p> <ul> <li>\"acc_scale\": 9.80665,</li> <li>\"imu_topic\": \"/livox/imu\",</li> <li>\"points_topic\": \"/livox/lidar\",</li> </ul>"},{"location":"demo.html#indoor-mapping-with-azure-kinect","title":"Indoor mapping with Azure Kinect","text":""},{"location":"demo.html#real-time-mapping-on-jetson-nano","title":"Real-time mapping on Jetson Nano","text":"<ul> <li>os1_128_01_downsampled.bag (515MB)</li> <li>config_nano_cpu.zip</li> <li>config_nano_gpu.zip</li> </ul> <p>Note</p> <ul> <li>Only odometry estimation was performed, no global optimization.</li> <li>Visualization was run on another PC that received points and pose messages via ethernet.   (rviz took about a half of Jetson Nano's computation capability without rendering anything!!)</li> <li>(2024/07/04) The current version of GLIM does not support CUDA 11 and older. Some minor midifications are expected to be necessary.</li> </ul>"},{"location":"docker.html","title":"Docker images","text":""},{"location":"docker.html#note","title":"Note","text":"<p>We recommend binary installation via PPA. See Installation page.</p>"},{"location":"docker.html#prebuilt-docker-images","title":"Prebuilt docker images","text":"<p>We provide the following docker images for ROS2 on docker hub.</p> <ul> <li> koide3/glim_ros2:jazzy</li> <li> koide3/glim_ros2:jazzy_cuda13.1</li> <li> koide3/glim_ros2:humble</li> <li> koide3/glim_ros2:humble_cuda12.2</li> </ul> <p>Note</p> <p>ROS2 sometimes requires additional configurations for communication on docker. See https://github.com/eProsima/Fast-DDS/issues/2956. Do not ask us about how to use ROS2 with docker.</p> <p>Note</p> <p>Currently, we provide only AMD64 images. ARM64 support is planned in the future.</p>"},{"location":"docker.html#example-use","title":"Example use","text":""},{"location":"docker.html#with-gpu","title":"With GPU","text":"<pre><code># Copy config and edit as you want\ngit clone git@github.com:koide3/glim /tmp/glim\ncp -R /tmp/glim/config ./config\n\n# Pull image from docker hub\ndocker pull koide3/glim_ros2:humble_cuda12.2\n\n# Launch glim_ros2:humble_cuda12.2 image with GPU and DISPLAY support\ndocker run \\\n  -it \\\n  --rm \\\n  --net=host \\\n  --ipc=host \\\n  --pid=host \\\n  --gpus all \\\n  -e=DISPLAY \\\n  -e=ROS_DOMAIN_ID \\\n  -v $(realpath config):/glim/config \\\n  koide3/glim_ros2:humble_cuda12.2 \\\n  ros2 run glim_ros glim_rosnode --ros-args -p config_path:=/glim/config\n</code></pre>"},{"location":"docker.html#without-gpu","title":"Without GPU","text":"<pre><code># Copy config and edit it\ngit clone git@github.com:koide3/glim /tmp/glim\ncp -R /tmp/glim/config ./config\n\n# Change as follows:\n# \"config_odometry\" : \"config_odometry_cpu.json\"\n# \"config_sub_mapping\" : \"config_sub_mapping_cpu.json\"\n# \"config_global_mapping\" : \"config_global_mapping_cpu.json\"\nnano config/config.json\n\n# Pull image from docker hub\ndocker pull koide3/glim_ros2:humble\n\n# Launch glim_ros2:humble image with DISPLAY support\ndocker run \\\n  -it \\\n  --rm \\\n  --net=host \\\n  --ipc=host \\\n  --pid=host \\\n  --gpus all \\\n  -e=DISPLAY \\\n  -e=ROS_DOMAIN_ID \\\n  -v $(realpath config):/glim/config \\\n  koide3/glim_ros2:humble \\\n  ros2 run glim_ros glim_rosnode --ros-args -p config_path:=/glim/config\n</code></pre>"},{"location":"docker.html#build-docker-images-from-source","title":"Build docker images from source","text":"<pre><code>mkdir /tmp/glim_docker &amp;&amp; cd /tmp/glim_docker\ngit clone git@github.com:koide3/glim\ngit clone git@github.com:koide3/glim_ros2\n\n# Without GPU\ndocker build \\\n  -f glim_ros2/docker/Dockerfile.gcc \\\n  --build-arg=\"BASE_IMAGE=koide3/gtsam_points:jammy\" \\\n  --build-arg=\"ROS_DISTRO=humble\" \\\n  --tag glim_ros2:humble \\\n  .\n\n# With GPU\ndocker build \\\n  -f glim_ros2/docker/Dockerfile.gcc.cuda \\\n  --build-arg=\"BASE_IMAGE=koide3/gtsam_points:jammy_cuda12.2\" \\\n  --build-arg=\"ROS_DISTRO=humble\" \\\n  --tag glim_ros2:humble_cuda12.2 \\\n  .\n</code></pre>"},{"location":"edit.html","title":"Manual Object Removal","text":""},{"location":"edit.html#about","title":"About","text":"<p>Interactive map editor allows users to manually annotate and remove object points from the map. This is useful for removing objects that are not relevant to the mapping task, such as trees, cars, and pedestrians.</p> <p>Note that while editing the map, the submap poses (i.e., factor graph) are frozen and not updated. If you need to update the submap poses, please use the offline viewer.</p>"},{"location":"edit.html#example","title":"Example","text":"<p>Example dump data:  </p> <ul> <li>inarimae_mmm.tar.gz [245MB] (3 sessions in large outdoor)</li> </ul>"},{"location":"edit.html#start-map-editor","title":"Start map editor","text":"<pre><code>ros2 run glim_ros map_editor\n</code></pre>"},{"location":"edit.html#open-a-mapping-result","title":"Open a mapping result","text":"<ul> <li><code>File</code> -&gt; <code>Open New Map</code> -&gt; Select a dump directory and click <code>Open</code>.</li> </ul>"},{"location":"edit.html#object-selection-and-removal-mincut-segmentation","title":"Object selection and removal (MinCut segmentation)","text":"<ul> <li>Right click a point on an object to be removed to open a context menu.</li> <li><code>Segmentation</code> -&gt; Select <code>MinCut</code> -&gt; Adjust <code>Foreground radius</code> and <code>Background radius</code><ul> <li>Points in the foreground radius (shown by a red sphere) are labeled as foreground</li> <li>Points outside the background radius (shown by a blue sphere) are labeled as background</li> </ul> </li> <li>Click <code>Segment</code> to segment the object</li> <li>Click <code>Remove selected points</code> to remove the selected points from the map</li> </ul> Context menu Selected points After removal"},{"location":"edit.html#plane-selection-and-removal-region-growing-segmentation","title":"Plane selection and removal (Region growing segmentation)","text":"<ul> <li>Right click a point on a plane to be removed to open a context menu.</li> <li><code>Segmentation</code> -&gt; Select <code>RegionGrowing</code> -&gt; Adjust <code>Angle threshold</code> and <code>Distance threshold</code></li> <li>Click <code>Segment</code> to segment the plane</li> <li>Click <code>Remove selected points</code> to remove the selected points from the map</li> </ul> Context menu Selected points"},{"location":"edit.html#manual-points-selection-and-removal-gizmo-ui","title":"Manual points selection and removal (Gizmo UI)","text":"<ul> <li>Click the checkbox just left to <code>Selection tool</code> to show the Gizmo UI.<ul> <li>It is also possible to show the Gizmo UI by clicking <code>Show Gizmo here</code> from the right-click context menu.</li> </ul> </li> <li>Manipulate the Gizmo UI to cover the points to be removed.</li> <li>Click <code>Select points</code> to select the points covered by the Gizmo UI.</li> <li>Click <code>Remove selected points</code> to remove the selected points from the map</li> </ul> Gizmo UI Selected points"},{"location":"edit.html#radius-selection-and-removal","title":"Radius selection and removal","text":"<ol> <li>Right click a point on the map to open a context menu.</li> <li><code>Radius tools</code> -&gt; Adjust <code>Radius</code> so that it covers the points to be removed -&gt; Click <code>Select points within radius</code>.</li> <li>Click <code>Remove selected points</code> to remove the selected points from the map</li> </ol>"},{"location":"edit.html#radius-outlier-removal-noise-removal","title":"Radius outlier removal (Noise removal)","text":"<ol> <li>Right click a point on the map to open a context menu.</li> <li><code>Radius tools</code> -&gt; Adjust <code>Radius</code> so that it covers the outlier points to be removed -&gt; Click <code>Select points outside radius</code>.</li> <li>Click <code>Remove selected points</code> to remove the selected points from the map</li> </ol> Context menu Selected points After removal"},{"location":"extend.html","title":"Extending GLIM","text":""},{"location":"extend.html#notation","title":"Notation","text":"<p>In this package, the (SE3) transformation from frame B to frame A is denoted as <code>T_A_B</code>. In other words, a point <code>p_B</code> in the frame B is transformed into the frame A by <code>T_A_B</code> (i.e., <code>p_A = T_A_B * p_B</code>).</p> <p>For instance, the transformation from a LiDAR frame to the world frame (i.e., a LiDAR pose in the world frame) is represented as <code>T_world_lidar</code>, and a point in the LiDAR frame <code>p_lidar</code> is transformed into the world frame by <code>p_world = T_world_lidar * p_lidar</code>.</p> <p>Similarty, <code>v_A_B</code> represents the velocity of frame B in frame A, and thus <code>v_world_imu</code> represents an IMU velocity in the world frame.</p>"},{"location":"extend.html#variables","title":"Variables","text":""},{"location":"extend.html#variable-addressing-in-gtsam","title":"Variable addressing in GTSAM","text":"<p>In GTSAM, variables can be addressed using the gtsam::Symbol class that combines a symbol label (a character, e.g., 'x') and a variable index. For example, you can insert a pose variable into gtsam::Values and label it as <code>X(i)</code> as follows:</p> <pre><code>using gtsam::symbol_shorthand::X;\n\nint id = 0;\ngtsam::Pose3 pose;\n\ngtsam::Values values;\nvalues.insert(X(id), pose);\n</code></pre> <p>Info</p> <p>See 5.2. Keys and Symbols in this tutorial for more details.</p>"},{"location":"extend.html#variables-in-glim","title":"Variables in GLIM","text":"<p>In the following, we show the graph structures and variables in the odometry estimation and global optimization algorithms of GLIM. Through the global callback slot mechanism, which will be explained later, you can access variables in the factor graphs and create additional constraints (i.e., factors) to improve the accuracy/stability/robustness of the mapping process in specific situations.</p>"},{"location":"extend.html#variables-in-the-odometry-estimation","title":"Variables in the odometry estimation","text":"<ul> <li><code>X(i)</code> : IMU pose = T_odom_imu (gtsam::Pose3)</li> <li><code>V(i)</code> : IMU velocity = v_odom_imu (gtsam::Vector3)</li> <li><code>B(i)</code> : IMU bias (gtsam::imuBias::ConstantBias)</li> </ul> <p>Note</p> <p>In the odometry estimation, old variables are eliminated from the graph when they leave the sliding optimization window specified by the smoother_lag param (e.g., 5 sec). You thus need to ensure that additional factors refer to only variables in this optimization window. </p> <p>Note</p> <p>Because odometry_ct performs LiDAR-only estimation, it does not create <code>V(i)</code> and <code>B(i)</code>, and <code>X(i)</code> represents the LiDAR pose instead of the IMU pose.</p> <p>Info</p> <p>\"velocity_suppressor.cpp\" in gtsam_points shows a simple example to insert velocity suppression factors into the odometry estimation factor graph.</p>"},{"location":"extend.html#variables-in-the-global-optimization","title":"Variables in the global optimization","text":"<p>Sub mapping states:</p> <ul> <li><code>X(i)</code> : Sensor pose = T_odom_sensor (gtsam::Pose3)</li> <li><code>V(i)</code> : IMU velocity = v_odom_sensor (gtsam::Vector3)</li> <li><code>B(i)</code> : IMU bias (gtsam::imuBias::ConstantBias)</li> </ul> <p>Global mapping states:</p> <ul> <li><code>X(i)</code> : Submap pose = T_world_submap (gtsam::Pose3)</li> <li><code>V(2 * i) &amp; V(2 * i + 1)</code> : IMU velocity at endpoints (gtsam::Vector3)</li> <li><code>B(2 * i) &amp; V(2 * i + 1)</code> : IMU bias at endpoints (gtsam::Vector3)</li> </ul>"},{"location":"extend.html#global-callback-slot","title":"Global callback slot","text":"<p>The global callback slot is a mechanism to hook processing steps in the mapping system. It enables to access the internal states of the mapping process and insert additional factors into the factor graph. The following code demonstrates how we can register a callback function to the new frame creation event in the odometry estimation and retrieve estimated sensor states of the latest frame.</p> <pre><code>#include &lt;glim/odometry/callback.hpp&gt;\n\nusing namespace glim;\n\nvoid on_new_frame(const EstimationFrame::ConstPtr&amp; new_frame) {\n  const long id = new_frame-&gt;id;                                    // Frame ID\n  const double stamp = new_frame-&gt;stamp;                            // Timestamp\n  const Eigen::Isometry3d&amp; T_world_imu = new_frame-&gt;T_world_imu;    // IMU pose\n}\n\nvoid setup_callback() {\n  using std::placeholders::_1;\n  OdometryEstimationCallback::on_new_frame.add(std::bind(&amp;on_new_frame, _1));\n}\n</code></pre> <p>Take a look at the following links to see what can be retrieved from and inserted into the system via global callback slots:</p> <ul> <li>OdometryEstimationCallbacks</li> <li>SubMappingCallbacks</li> <li>GlobalMappingCallbacks</li> </ul> <p>Warning</p> <p>Each of odometry estimation, submapping, and global mapping modules are run in different threads, and thus their callbacks can be called from different threads. You must take care of the thread-safety of your extension module if it subscribes to events from different modules.</p>"},{"location":"extend.html#extension-module","title":"Extension module","text":"<p>GLIM offers a mechanism to load extension modules from shared libraries at run-time. To implement an extension module, you need to write your extension module class that inherits from glim::ExtensionModule and define a loading function named create_extension_module() that returns an instance of your extension class.</p> my_extension_module.cpp<pre><code>#include &lt;glim/odometry/callbacks.hpp&gt;\n#include &lt;glim/util/extension_module.hpp&gt;\n\nusing namespace glim;\n\nclass MyExtensionModule : public ExtensionModule {\npublic:\n  MyExtensionModule() {\n    using std::placeholders::_1;\n    OdometryEstimationCallbacks::on_new_frame.add(std::bind(&amp;MyExtensionModule::on_new_frame, this, _1));\n  }\n\n  void on_new_frame(const EstimationFrame::ConstPtr&amp; frame) {\n    // ...\n  }\n};\n\nextern \"C\" ExtensionModule* create_extension_module() {\n  return new MyExtensionModule();\n}\n</code></pre> CMakeLists.txt<pre><code>cmake_minimum_required(VERSION 3.5.2)\nproject(my_extension_module)\n\nset(CMAKE_CXX_STANDARD 17)\n\nfind_package(glim REQUIRED)\n\nadd_library(my_extension_module SHARED\n  src/my_extension_module.cpp\n)\ntarget_link_libraries(my_extension_module\n  glim::glim\n)\n</code></pre> <p>The extension module can be loaded into GLIM by adding the name of the created shared library to <code>extension_modules</code> parameter in <code>glim/config/config_ros.json</code>.</p> <p>Note</p> <p>If you don't want to use the dynamic loading mechanism, it is also possible to create an extension by directly modifying <code>glim_ros.cpp</code>, of course.</p>"},{"location":"extensions.html","title":"Extension modules","text":""},{"location":"extensions.html#open-source-extension-modules","title":"Open-source extension modules","text":"<p>glim_ext provides example implementations of extension modules that demonstrate the extensibility of GLIM. All the implemented modules are decoupled from GLIM main components and inter-module communication is conducted via the global callback slot mechanism.</p> <p>Warning</p> <p>The implementations in glim_ext are proof-of-concept code for showing the extensibility of GLIM. They may not be well-maintained and may not be suitable for practical purposes.</p> <p>Warning</p> <p>Each module in glim_ext uses several external libraries that employ different licenses. You must carefully check and follow their licensing conditions.</p>"},{"location":"extensions.html#installation","title":"Installation","text":"<pre><code>cd ~/ros2_ws/src\ngit clone https://github.com/koide3/glim_ext\n\ncd ~/ros2_ws\ncolcon build\n</code></pre>"},{"location":"extensions.html#odometry-estimation-modules","title":"Odometry estimation modules","text":""},{"location":"extensions.html#orb_slam-based-loose-visual-integration","title":"ORB_SLAM-based loose visual integration","text":"<ul> <li>Loosely coupled visual odometry estimation constraints based on ORB_SLAM3</li> <li>Dependency: ORB_SLAM3 (GPL-3.0)</li> </ul>"},{"location":"extensions.html#velocity-suppressor","title":"Velocity suppressor","text":"<ul> <li>Constraints to regulate IMU velocity</li> </ul>"},{"location":"extensions.html#imu-calibration-validator","title":"IMU calibration validator","text":"<ul> <li>Utility module to validate the LiDAR-IMU transformation (See FAQ)</li> </ul>"},{"location":"extensions.html#global-optimization-modules","title":"Global optimization modules","text":""},{"location":"extensions.html#gnss-constraints-ros2-only","title":"GNSS constraints [ROS2 only]","text":"<ul> <li>Naive implementation of GNSS global optimization constraints</li> </ul>"},{"location":"extensions.html#scancontext-loop-detector","title":"ScanContext loop detector","text":"<ul> <li>Explicit loop detection based on ScanContext</li> <li>Dependency: ScanContext (CC BY-NC-SA 4.0)</li> </ul>"},{"location":"extensions.html#dbow-loop-detector","title":"DBoW loop detector","text":"<ul> <li>Explicit loop detection based on DBoW3</li> <li>Dependency: DBoW3 (LICENSE)</li> </ul>"},{"location":"extensions.html#closed-source-extension-modules","title":"Closed-source extension modules","text":"<p>The following modules are provided as closed-source packages. Contact us if you are interested in the closed-source modules.</p>"},{"location":"extensions.html#tightly-coupled-multi-lidar-odometry-estimation-module","title":"Tightly-coupled multi-LiDAR odometry estimation module","text":""},{"location":"extensions.html#tightly-coupled-multi-camera-odometry-estimation-module","title":"Tightly-coupled multi-camera odometry estimation module","text":""},{"location":"extensions.html#dense-mapping-and-colorization-module","title":"Dense mapping and colorization module","text":""},{"location":"faq.html","title":"FAQ","text":"<p>Moved to wiki/FAQ.</p>"},{"location":"installation.html","title":"Installation","text":"<p>GLIM is tested on Ubuntu 22.04 / 24.04 with CUDA 12.2 / 12.6 / 13.1, and NVIDIA Jetson Orin (JetPack 6.1). You can build and install GLIM from source code, or install pre-built binaries from PPA.</p>"},{"location":"installation.html#install-from-ppa-ubuntu-2404-2204-amd64-arm64","title":"Install from PPA [Ubuntu 24.04, 22.04] [AMD64, ARM64]","text":""},{"location":"installation.html#prerequisite","title":"Prerequisite","text":"<pre><code>sudo apt install curl gpg\n</code></pre>"},{"location":"installation.html#setup-ppa","title":"Setup PPA","text":"<pre><code># Automatically setup PPA via online script\ncurl -s https://koide3.github.io/ppa/setup_ppa.sh | sudo bash\n</code></pre> Manually setup PPA (If you don't want to use the online script) <pre><code># Manually setup PPA for Ubuntu 24.04\ncurl -s --compressed \"https://koide3.github.io/ppa/ubuntu2404/KEY.gpg\" | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/koide3_ppa.gpg &gt;/dev/null\necho \"deb [signed-by=/etc/apt/trusted.gpg.d/koide3_ppa.gpg] https://koide3.github.io/ppa/ubuntu2404 ./\" | sudo tee /etc/apt/sources.list.d/koide3_ppa.list\nsudo apt update\n\n# Manually setup PPA for Ubuntu 22.04\ncurl -s --compressed \"https://koide3.github.io/ppa/ubuntu2204/KEY.gpg\" | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/koide3_ppa.gpg &gt;/dev/null\necho \"deb [signed-by=/etc/apt/trusted.gpg.d/koide3_ppa.gpg] https://koide3.github.io/ppa/ubuntu2204 ./\" | sudo tee /etc/apt/sources.list.d/koide3_ppa.list\nsudo apt update\n</code></pre>"},{"location":"installation.html#install-dependencies","title":"Install dependencies","text":"<pre><code>sudo apt update\nsudo apt install -y libiridescence-dev libboost-all-dev libglfw3-dev libmetis-dev\n\n# Choose one of the follows\nsudo apt install -y libgtsam-points-dev           # without CUDA\nsudo apt install -y libgtsam-points-cuda12.2-dev  # with CUDA 12.2 (Ubuntu 22.04 only)\nsudo apt install -y libgtsam-points-cuda12.6-dev  # with CUDA 12.6\nsudo apt install -y libgtsam-points-cuda13.1-dev  # with CUDA 13.1\n</code></pre>"},{"location":"installation.html#install-glim-for-ros2","title":"Install GLIM for ROS2","text":"<pre><code># Choose one of the follows\n\n# ROS2 jazzy (Ubuntu 24.04)\nsudo apt install -y ros-jazzy-glim-ros             # Without CUDA\nsudo apt install -y ros-jazzy-glim-ros-cuda12.6    # With CUDA 12.6\nsudo apt install -y ros-jazzy-glim-ros-cuda13.1    # With CUDA 13.1\n\n# ROS2 humble (Ubuntu 22.04)\nsudo apt install -y ros-humble-glim-ros            # Without CUDA\nsudo apt install -y ros-humble-glim-ros-cuda12.2   # With CUDA 12.2\nsudo apt install -y ros-humble-glim-ros-cuda12.6   # With CUDA 12.6\nsudo apt install -y ros-humble-glim-ros-cuda13.1   # With CUDA 13.1\n</code></pre> <pre><code># After installation, make shared libraries visible to the system\nsudo ldconfig\n</code></pre>"},{"location":"installation.html#install-from-source","title":"Install from source","text":""},{"location":"installation.html#common-dependencies","title":"Common dependencies","text":"<pre><code># Install dependencies\nsudo apt install libomp-dev libboost-all-dev libmetis-dev \\\n                 libfmt-dev libspdlog-dev \\\n                 libglm-dev libglfw3-dev libpng-dev libjpeg-dev\n\n# Install GTSAM\ngit clone https://github.com/borglab/gtsam\ncd gtsam &amp;&amp; git checkout 4.3a0\nmkdir build &amp;&amp; cd build\ncmake .. -DGTSAM_BUILD_EXAMPLES_ALWAYS=OFF \\\n         -DGTSAM_BUILD_TESTS=OFF \\\n         -DGTSAM_WITH_TBB=OFF \\\n         -DGTSAM_USE_SYSTEM_EIGEN=ON \\\n         -DGTSAM_BUILD_WITH_MARCH_NATIVE=OFF\nmake -j$(nproc)\nsudo make install\n\n# Install Iridescence for visualization\n# This is optional but highly recommended\ngit clone https://github.com/koide3/iridescence --recursive\nmkdir iridescence/build &amp;&amp; cd iridescence/build\ncmake .. -DCMAKE_BUILD_TYPE=Release\nmake -j$(nproc)\nsudo make install\n\n\n# Install gtsam_points\ngit clone https://github.com/koide3/gtsam_points\nmkdir gtsam_points/build &amp;&amp; cd gtsam_points/build\ncmake .. -DBUILD_WITH_CUDA=ON\nmake -j$(nproc)\nsudo make install\n\n\n# Make shared libraries visible to the system\nsudo ldconfig\n</code></pre>"},{"location":"installation.html#install-glim-for-ros2_1","title":"Install GLIM for ROS2","text":"<pre><code>cd ~/ros2_ws/src\ngit clone https://github.com/koide3/glim\ngit clone https://github.com/koide3/glim_ros2\n\ncd ~/ros2_ws\ncolcon build\n\n# cmake options\n# colcon build --cmake-args \\\n#   -DBUILD_WITH_CUDA=ON \\\n#   -DBUILD_WITH_VIEWER=ON \\\n#   -DBUILD_WITH_MARCH_NATIVE=OFF\n</code></pre> <p>Note</p> <p>While AVX intrinsics can be enabled to speed up the mapping process by setting <code>BUILD_WITH_MARCH_NATIVE=ON</code>, it sometimes causes segfaults unless <code>march=native</code> is properly set for every involved library. We recommend keeping it disabled if you are not sure.</p>"},{"location":"merge.html","title":"Merging Sessions","text":""},{"location":"merge.html#about","title":"About","text":"<p>You can merge multiple mapping sessions into a single map using the offline viewer. This is useful when you want to create a large map from multiple mapping sessions, or when you want to improve the global consistency of the map by merging multiple sessions.</p> <p>Note</p> <p>The map data is likely to be broken when warnings like <code>[global] [warning] X34 -&gt; E69 is missing</code> are shown, and the optimization may get corrupted when merging broken map data. Before merging sessions, make sure each map data is not broken. A broken map can be repaired by clicking <code>Recover graph</code>. You have to repair maps one by one (Load a broken map -&gt; repair it -&gt; save it -&gt; close it, then do so for the next map).</p>"},{"location":"merge.html#example","title":"Example","text":"<p>Example dump data:  </p> <ul> <li>mmm.tar.gz [32MB] (3 indoor sessions)</li> <li>inarimae_mmm.tar.gz [245MB] (3 sessions in large outdoor)</li> </ul>"},{"location":"merge.html#start-offline-viewer","title":"Start offline viewer","text":"<pre><code>ros2 run glim_ros offline_viewer\n</code></pre>"},{"location":"merge.html#open-mapping-sessions","title":"Open mapping sessions","text":"<ol> <li>Open the first session : <code>File</code> -&gt; <code>Open New Map</code> -&gt; <code>Select the first dump directory</code> -&gt; Select <code>Yes</code> on the dialog to enable optimization.</li> <li>Open the second session : <code>File</code> -&gt; <code>Open Additional Map</code> -&gt; <code>Select the second dump directory</code>.</li> </ol>"},{"location":"merge.html#merge-sessions","title":"Merge sessions","text":"<ol> <li>Click <code>Merge sessions</code></li> <li>Choose the default registration parameter set (<code>Indoor</code> or <code>Outdoor</code>) and click <code>OK</code></li> <li>Align point clouds using automatic or manual alignment<ul> <li>Automatic alignment : <code>Run global registration</code> and check if the point clouds are roughly aligned</li> <li>Manual alignment : Roughly align the source points (green) with the target points (red) by manipulating the Gizmo UI.</li> </ul> </li> <li>Click <code>Run fine registration</code> to perform ICP matching</li> <li>Click <code>Create factor</code> to merge sessions</li> </ol>"},{"location":"merge.html#fuse-sessions-global-matching-cost-minimization","title":"Fuse sessions (Global matching cost minimization)","text":"<ol> <li>Click <code>Find overlapping submaps</code> to create matching cost factors between overlapping submaps. This improves the global consistency between sessions.</li> <li>Click <code>Optimize</code> several times to run optimization steps (Or click the check box to continuously run optimization)</li> </ol> Merge result Merge result (Colored by session ID) Factor graph"},{"location":"parameters.html","title":"Important parameters","text":"<p>Info</p> <p>See the sensor setup buide for configurations of popular sensors (including Livox MID360 and Azure Kinect).</p> <p>Info</p> <p>See the Configuration files section in Getting started to change the location of configuration files.</p>"},{"location":"parameters.html#ros-related-config_rosjson","title":"ROS-related (config_ros.json)","text":"<ul> <li>acc_scale (default 1.0) : Linear acceleration scaling factor. Set this to 9.80665 if the unit of IMU linear acceleration is [g] but not [m/s^2] (e.g., Livox LiDARs). </li> <li>(imu|points|image)_topics : Input data topics.</li> </ul>"},{"location":"parameters.html#sensor-configuration-config_sensorsjson","title":"Sensor configuration (config_sensors.json)","text":"<ul> <li>T_lidar_imu : Transformation from the IMU frame to the LiDAR frame (See notation). When the IMU is at rest and the IMU z-axis points upwards, linear acceleration vector should be around [0, 0, +9.81] (See also ROS REP 145 and FAQ).</li> </ul>"},{"location":"parameters.html#preprocessing-config_preprocessjson","title":"Preprocessing (config_preprocess.json)","text":"<ul> <li> <p>random_downsample_target (default 10000 points): Target number of points for downsampling. Reducing the target number of points (e.g., to 5000) makes estimation significantly faster.</p> </li> <li> <p>k_correspondences (default 10 points): The number of neighboring points used for covariance estimation. For LiDARs with sparse scan patterns (e.g., Velodyne VLP16), increase this value to 15 ~ 30 to avoid degeneration of covariance matrices.</p> </li> </ul> <p>Note</p> <p>To see if estimated covariances are fine, change <code>color_mode</code> in the standard viewer to <code>NORMAL</code>. If point colors are uniform on flat planes, covariances should be ok.</p>"},{"location":"parameters.html#gpu-based-lidar-imu-odometry-estimation-config_odometryjson","title":"GPU-based LiDAR-IMU Odometry Estimation (config_odometry.json)","text":"<ul> <li>voxel_resolution (default 0.25 m) : Base VGICP voxel resolution. Use a small value for indoor environments (e.g., 0.1 ~ 0.25 m).</li> <li>voxelmap_levels (default 2 levels): Multi resolution voxel levels. Increasing this parameter makes estimation robust to large displacement.</li> <li>max_num_keyframes (default 15 keyframes): Maximum number of keyframes. Increasing this parameter reduces odometry estimation drift.</li> <li>keyframe_update_strategy (default OVERLAP): \"OVERLAP\", \"DISPLACEMENT\", or \"ENTROPY\". <ul> <li>\"OVERLAP\" uses an overlap-metric-based keyframe management strategy that can adaptively deal with many environments (indoors and outdoors). Increasing keyframe_max_overlap makes keyframe insertion more frequent and robust to dynamic situations.</li> <li>\"DISPLACEMENT\" uses the conventional displacement-based keyframe management that is more intuitive to tune. Change keyframe_delta_(trans|rot) to tune the keyframe insertion frequency.</li> <li>\"ENTROPY\" uses an entropy-based keyframe management. This strategy is often difficult to tune and is not recommended.</li> </ul> </li> </ul>"},{"location":"parameters.html#cpu-based-lidar-imu-odometry-estimation-config_odometry_cpujson","title":"CPU-based LiDAR-IMU Odometry Estimation (config_odometry_cpu.json)","text":"<ul> <li> <p>registration_type (default GICP) : Either of \"GICP\" or \"VGICP\".</p> <ul> <li> <p>\"GICP\" uses iVox-based GICP scan matching that is accurate and robust in many cases.</p> <ul> <li>ivox_resolution (default 0.5 m) : Resolution of iVox voxels used for GICP scan matching. This parameter also controls the maximum corresponding distance and should be set to a large value in outdoor environments (e.g., 1.0 m).</li> </ul> </li> <li> <p>\"VGICP\" uses voxelized GICP scan matching that is faster but requires tuning vgicp_resolution parameter for good estimation in indoor environments.</p> <ul> <li>vgicp_resolution (default 0.5 m) : Resolution of VIGP voxels used for VGICP scan matching. Use a small value for indoor environments (e.g., 0.25 ~ 0.5 m) and a large value for outdoor environments (0.5 ~ 2.0 m).</li> </ul> </li> </ul> </li> </ul>"},{"location":"parameters.html#lidar-only-odometry-estimation-config_odometry_ctjson","title":"LiDAR-only Odometry Estimation (config_odometry_ct.json)","text":"<ul> <li>max_correspondence_distance (default 2.0 m) : Maximum corresponding distance for scan matching. </li> </ul>"},{"location":"parameters.html#global-optimization-config_sub_mappingjson-config_global_mappingjson","title":"Global Optimization (config_sub_mapping.json &amp; config_global_mapping.json)","text":""},{"location":"parameters.html#sub-mapping","title":"Sub mapping","text":"<ul> <li>enable_optimization (default true) : In environments where the odometry estimation is sufficiently robust and accurate, you can set this false to disable submap optimization and save the processing cost.</li> <li>keyframe-related params : These parameters control the keyframe creation in sub mapping. See GPU-based LiDAR-IMU odometry params for details.</li> </ul>"},{"location":"parameters.html#global-mapping","title":"Global mapping","text":"<ul> <li>min_implicit_loop_overlap (default 0.2) : Minimum overlap rate to create registration error factor.</li> </ul>"},{"location":"parameters.html#common-parameters-for-sub-and-global-mapping","title":"Common parameters for sub and global mapping","text":"<ul> <li>enable_imu (default true) : Must be false if the LiDAR-only odometry estimation is used.</li> <li>registration_error_factor_type (default \"VGICP_GPU\") : Registration error computation type. Must be either of \"VGICP\" or \"VGICP_GPU\".</li> <li>random_sampling_rate (default 1.0) : Random sampling rate for points used for registration error computation. With the GPU implementation, you can use a large random sampling rate (e.g., 1.0 = disabling random sampling) to perform full global registration error minimization.</li> <li>(submap|keyframe)_voxel_resolution (default 0.5 m) : Base voxel resolution. Set a small value (e.g., 0.15 ~ 0.25 m) for indoor environments.</li> <li>(submap|keyframe)_voxelmap_levels (default 2 levels) : Multi resolution voxel levels. Set this param to 2 or 3 for better convergence.</li> </ul>"},{"location":"quickstart.html","title":"Getting started","text":""},{"location":"quickstart.html#prerequisite","title":"Prerequisite","text":"<ol> <li>Install GLIM on your system following the installation section. Alternatively, you can also use prebuilt docker images.</li> <li> <p>Download test data.     ROS1: os1_128_01_downsampled.bag (515MB) or os1_128_01.bag (7.3GB)     ROS2: os1_128_01_downsampled.tar.gz (426MB) or os1_128_01.tar.gz (3.2GB)</p> <p>Alternative links: ROS1 (downsampled)  ROS2 (downsampled)</p> </li> <li> <p>Confirm that the sensor configuration and ROS topic parameters are set as follows: <pre><code>glim/config/config.json\n  \"config_odometry\": \"config_odometry_gpu.json\",\n  \"config_sub_mapping\": \"config_sub_mapping_gpu.json\",\n  \"config_global_mapping\": \"config_global_mapping_gpu.json\",\nglim/config/config_sensors.json\n  \"T_lidar_imu\": [-0.006, 0.012, -0.008, 0, 0, 0, 1],\nglim/config/config_ros.json\n  \"imu_topic\": \"/os_cloud_node/imu\",\n  \"points_topic\": \"/os_cloud_node/points\",\n</code></pre></p> </li> </ol> <p>Tip</p> <p>If you want to try the CPU-based odometry estimation and global optimization, in <code>config.json</code>, set  <code>\"config_odometry\"</code> : <code>\"config_odometry_cpu.json\"</code>, <code>\"config_sub_mapping\"</code> : <code>\"config_sub_mapping_passthrough.json\"</code>, <code>\"config_global_mapping\"</code> : <code>\"config_global_mapping_pose_graph.json\"</code>,</p> <p>Tip</p> <p>If you want to try the LiDAR-only odometry estimation without IMU data,  in <code>config.json</code>, set <code>\"config_odometry\"</code> : <code>\"config_odometry_ct.json\"</code>, and, in <code>config_sub_mapping_gpu.json</code> and <code>config_global_mapping_gpu.json</code>, set <code>\"enable_imu\"</code> : <code>false</code></p> <p>Warning</p> <p>In ROS2, you need to re-run <code>colcon build</code> to apply config changes in the installed packages. See the configuration files section for more details.</p>"},{"location":"quickstart.html#executables","title":"Executables","text":"<p>GLIM provides two ROS executables: glim_rosnode and glim_rosbag.</p>"},{"location":"quickstart.html#glim_rosnode","title":"glim_rosnode","text":"<p>glim_rosnode launches GLIM as a standard ROS node that subscribes to points, imu, and image topics. </p> ROS2 command <pre><code>ros2 run glim_ros glim_rosnode\n</code></pre> <pre><code>ros2 bag play os1_128_01\n</code></pre> <pre><code>rviz2 -d glim_ros2/rviz/glim_ros.rviz\n</code></pre>"},{"location":"quickstart.html#glim_rosbag","title":"glim_rosbag","text":"<p>glim_rosbag launches a mapping instance that directly reads data from rosbag. It automatically adjusts the playback speed while avoiding data drop to perform mapping in a minimum time.</p> ROS2 command <pre><code>ros2 run glim_ros glim_rosbag os1_128_01\n</code></pre>"},{"location":"quickstart.html#configuration-files","title":"Configuration files","text":"<p>GLIM reads parameter settings from JSON files in a config root directory, which is set to <code>glim/config</code> by default. It first reads <code>config.json</code> that describes relative paths to submodule parameter files, and then reads parameters of submodules from specified configuration files. The config root directory can be changed by setting <code>config_path</code> ROS param when starting GLIM executables.</p> <p>Note</p> <p>If <code>config_path</code> starts with \"/\", the path is interpreted as an absolute path. Otherwise, <code>config_path</code> is interpreted as a path relative to <code>glim</code> package directory. <code>realpath</code> command is useful to run GLIM with local configuration files out of the package directory: (e.g., <code>ros2 run glim_ros glim_rosnode --ros-args -p config_path:=$(realpath config)</code>)</p> <p>Note</p> <p>On ROS2, you need to run <code>colcon build</code> to apply changes of the configuration files in the package directory because ROS2 requires to place config files in the install directory. To avoid this, use <code>--symlink-install</code> option for <code>colcon build</code>.</p> <p>Info</p> <p>See Important parameters to understand parameters that should be fine-tuned.</p> <p>Example</p> ROS2 command <pre><code># Load parameters from \"glim/config/presets/gpu/config.json\"\nros2 run glim_ros glim_rosnode --ros-args -p config_path:=config/presets/gpu\n\n# Load parameters from \"/tmp/config/config.json\"\nros2 run glim_ros glim_rosnode --ros-args -p config_path:=/tmp/config\n\n# Load parameters from \"./config/config.json\"\nros2 run glim_ros glim_rosnode --ros-args -p config_path:=$(realpath ./config)\n</code></pre>"},{"location":"quickstart.html#mapping-result","title":"Mapping result","text":"<p>The mapping result data (dump data) will be saved in <code>/tmp/dump</code> when closing glim_rosnode or glim_rosbag. The dump data can be visualized and edited using the offline viewer (<code>rosrun glim_ros offline_viewer</code>).</p> <p>The dump directory contains mapping graph data as well as the following estimated trajectory files.</p> <p>Estimated trajectory files (TUM format : Each row is [t x y z qx qy qz qw]):</p> <ul> <li>odom_imu.txt : Trajectory of the IMU frame without loop closure (Odometry result)</li> <li>traj_imu.txt : Trajectory of the IMU frame with loop closure (Global mapping result)</li> <li>odom_lidar.txt : Trajectory of the LiDAR frame without loop closure (Odometry result)</li> <li>traj_lidar.txt : Trajectory of the LiDAR frame with loop closure (Global mapping result)</li> </ul> <p>Example dump data: dump_rosbag2_2024_04_16-14_17_01.tar.gz (trajectory errors are injected for manual loop closure test)</p>"},{"location":"quickstart.html#offline-viewer-manual-map-editing-and-point-cloud-export","title":"Offline viewer (manual map editing and point cloud export)","text":"<pre><code># ROS2\nros2 run glim_ros offline_viewer\n</code></pre>"},{"location":"quickstart.html#open-map","title":"Open map","text":"<p><code>File</code> -&gt; <code>Open Map</code> -&gt; Select a dump directory.</p>"},{"location":"quickstart.html#create-explicit-loop-constraints","title":"Create explicit loop constraints","text":"<ul> <li><code>Right click a submap sphere</code> -&gt; <code>Loop begin</code> -&gt; <code>Right click another submap sphere</code> -&gt; <code>Loop end</code></li> <li>Roughly align red and green point clouds -&gt; Press <code>Align</code> to perform scan matching -&gt; Press <code>Create Factor</code> if the alignment result is fine.</li> </ul>"},{"location":"quickstart.html#create-plane-ba-constraints","title":"Create Plane-BA constraints","text":"<ul> <li><code>Right click a point on a flat surface</code> -&gt; <code>Bundle Adjustment (Plane)</code></li> <li>Adjust the sphere size so it covers sufficient points on the plane -&gt; <code>Create Factor</code></li> </ul>"},{"location":"quickstart.html#export-map-point-cloud-ply-format","title":"Export map point cloud (PLY format)","text":"<ul> <li><code>File</code> -&gt; <code>Save</code> -&gt; <code>Export Points</code></li> </ul>"},{"location":"quickstart.html#and-more","title":"... and more","text":"<ul> <li>Merging multiple mapping sessions (<code>offline_viewer</code>)</li> <li>Manual points selection and removal (<code>map_editor</code>)</li> </ul>"},{"location":"quickstart.html#setup-your-own-sensor","title":"Setup your own sensor","text":"<p>See Sensor setup guide.</p>"}]}